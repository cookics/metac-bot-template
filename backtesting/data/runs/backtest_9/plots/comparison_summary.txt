========================================================================================================================
BACKTEST MULTI-MODEL COMPARISON SUMMARY
========================================================================================================================

Category             | default                   | minimax-m2_1              | grok-4_1-fast             | grok-code-fast-1          | mimo-v2-flash_free        | glm-4_7                  
Model                | claude-opus-4.5           | minimax-m2.1              | grok-4.1-fast             | grok-code-fast-1          | mimo-v2-flash:free        | glm-4.7                  
------------------------------------------------------------------------------------------------------------------------
Binary Accuracy      |   82.4% (17q)           |   47.1% (17q)           |   64.7% (17q)           |   76.5% (17q)           |   70.6% (17q)           |   68.8% (16q)          
Binary Avg Peer      |       4.48                 |     -84.39                 |     -99.81                 |     -23.05                 |     -59.14                 |     -65.57                
Multiple_choice Avg Peer |      14.83                 |     -54.28                 |      20.59                 |       1.76                 |       2.29                 |      -7.72                
Numeric Avg Peer     |     -22.59                 |     -28.32                 |     -28.68                 |     -31.68                 |     -38.77                 |      -7.34                
------------------------------------------------------------------------------------------------------------------------
OVERALL AVG PEER     |      -1.41                 |     -55.69                 |     -37.10                 |     -18.05                 |     -32.56                 |     -26.87                
